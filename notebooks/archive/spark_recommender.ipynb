{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b08962",
   "metadata": {},
   "source": [
    "# Spark Recommender - Interactive Notebook\n",
    "\n",
    "This notebook demonstrates the Spark Recommender system components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda8c43",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, let's import the required libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e11a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import our modules\n",
    "from mcp_server.kusto_client import KustoClient\n",
    "from rag.indexer import SparkDocIndexer\n",
    "from rag.retriever import SparkDocRetriever\n",
    "from agent.orchestrator import SparkRecommenderAgent\n",
    "from agent.judge import JudgeAgent\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5b28da",
   "metadata": {},
   "source": [
    "## 2. Index Spark Documentation\n",
    "\n",
    "Index documentation files into Azure AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c40f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the indexer\n",
    "indexer = SparkDocIndexer()\n",
    "\n",
    "# Create the search index\n",
    "indexer.create_index()\n",
    "print(\"✓ Search index created\")\n",
    "\n",
    "# Index documents from the docs folder\n",
    "docs_path = \"rag/docs\"\n",
    "result = indexer.index_from_directory(docs_path)\n",
    "print(f\"✓ Indexed documents: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207b481",
   "metadata": {},
   "source": [
    "## 3. Test Document Retrieval\n",
    "\n",
    "Test retrieving relevant documentation based on a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c07eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize retriever\n",
    "retriever = SparkDocRetriever()\n",
    "\n",
    "# Test search\n",
    "query = \"How to optimize Spark shuffle operations?\"\n",
    "results = retriever.search(query, top_k=3)\n",
    "\n",
    "print(f\"Found {len(results)} relevant documents:\\n\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"{i}. {doc['title']} (score: {doc['score']:.2f})\")\n",
    "    print(f\"   {doc['content'][:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d182ae1",
   "metadata": {},
   "source": [
    "## 4. Query Kusto for Telemetry Data\n",
    "\n",
    "Retrieve Spark job telemetry from Kusto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf0976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Kusto client\n",
    "kusto = KustoClient()\n",
    "\n",
    "# Query recent Spark jobs\n",
    "query = \"\"\"\n",
    "SparkTelemetry\n",
    "| where timestamp > ago(1d)\n",
    "| take 10\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    results = kusto.query(query)\n",
    "    print(\"✓ Kusto query executed successfully\")\n",
    "    print(f\"Results: {results}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Kusto query failed: {e}\")\n",
    "    print(\"Make sure your Kusto credentials are configured correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61833056",
   "metadata": {},
   "source": [
    "## 5. Generate Recommendations\n",
    "\n",
    "Use the agent orchestrator to generate Spark optimization recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe64707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the recommender agent\n",
    "agent = SparkRecommenderAgent()\n",
    "\n",
    "# Example query\n",
    "user_question = \"My Spark job is taking too long. How can I optimize it?\"\n",
    "\n",
    "# Generate recommendation\n",
    "async def get_recommendation():\n",
    "    recommendation = await agent.get_recommendation(\n",
    "        user_query=user_question,\n",
    "        job_id=None  # Set to a specific job ID if you have one\n",
    "    )\n",
    "    return recommendation\n",
    "\n",
    "# Run async function\n",
    "recommendation = await get_recommendation()\n",
    "print(\"Recommendation:\")\n",
    "print(\"=\" * 80)\n",
    "print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6128f1e",
   "metadata": {},
   "source": [
    "## 6. Evaluate Recommendations\n",
    "\n",
    "Use the judge agent to evaluate recommendation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3df4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize judge\n",
    "judge = JudgeAgent()\n",
    "\n",
    "# Evaluate the recommendation\n",
    "async def evaluate():\n",
    "    evaluation = await judge.evaluate_recommendation(\n",
    "        recommendation=recommendation,\n",
    "        context=user_question\n",
    "    )\n",
    "    return evaluation\n",
    "\n",
    "evaluation_result = await evaluate()\n",
    "score = judge.parse_score(evaluation_result)\n",
    "\n",
    "print(\"Evaluation:\")\n",
    "print(\"=\" * 80)\n",
    "print(evaluation_result)\n",
    "print(f\"\\nQuality Score: {score}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a021d",
   "metadata": {},
   "source": [
    "## 7. End-to-End Example\n",
    "\n",
    "Complete workflow from query to evaluated recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cc544",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def full_recommendation_workflow(question: str, job_id: str = None):\n",
    "    \"\"\"Complete recommendation workflow\"\"\"\n",
    "    \n",
    "    print(f\"Question: {question}\\n\")\n",
    "    \n",
    "    # Step 1: Generate recommendation\n",
    "    print(\"Step 1: Generating recommendation...\")\n",
    "    rec = await agent.get_recommendation(question, job_id)\n",
    "    \n",
    "    # Step 2: Evaluate recommendation\n",
    "    print(\"Step 2: Evaluating quality...\")\n",
    "    eval_result = await judge.evaluate_recommendation(rec, question)\n",
    "    quality_score = judge.parse_score(eval_result)\n",
    "    \n",
    "    # Step 3: Display results\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RECOMMENDATION:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(rec)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Quality Score: {quality_score}/10\")\n",
    "    \n",
    "    return rec, quality_score\n",
    "\n",
    "# Run example\n",
    "test_question = \"What are the best practices for partitioning in Spark?\"\n",
    "await full_recommendation_workflow(test_question)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
