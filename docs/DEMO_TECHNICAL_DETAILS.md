# Spark Advisor Demo â€” Technical Architecture

## ğŸ“‹ Executive Summary

**What we built:** An AI-powered Spark performance advisor that combines:
- **Kusto (Eventhouse)** for telemetry data
- **RAG** (Retrieval Augmented Generation) for official documentation
- **LLM Judge** for recommendation validation
- **MCP** (Model Context Protocol) for tool integration
- **Multi-interface access** (Chainlit UI, VS Code Agent, Python API)

---

## ğŸ”§ Technology Stack

### Core Components

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **MCP Server** | FastMCP | 0.2.0 | Exposes Kusto tools to AI agents |
| **Orchestrator** | Semantic Kernel | 1.1.0 | Multi-step agent workflow |
| **LLM** | Azure OpenAI GPT-4o | - | Query generation, analysis, judge |
| **Vector Search** | Azure AI Search | 11.4.0 | RAG document retrieval |
| **Data Layer** | Azure Data Explorer (Kusto) | 4.4.0 | Spark telemetry storage |
| **Web UI** | Chainlit | 1.3.0+ | Interactive chat interface |
| **Auth** | Azure CLI | - | Unified credential provider |

---

## ğŸ—ï¸ Architecture Layers

### Layer 1: Data Sources (Truth Tier)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  KUSTO EVENTHOUSE (Primary Data Source)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Tables:                                                    â”‚
â”‚    â€¢ sparklens_metrics        â†’ Performance metrics        â”‚
â”‚    â€¢ sparklens_predictions    â†’ Scaling what-if analysis   â”‚
â”‚    â€¢ sparklens_recommedations â†’ SparkLens advice           â”‚
â”‚    â€¢ fabric_recommedations    â†’ Fabric-specific tips       â”‚
â”‚    â€¢ SparkEventLogs           â†’ Spark config (JSON blobs)  â”‚
â”‚                                                             â”‚
â”‚  Query: KQL (Kusto Query Language)                         â”‚
â”‚  Auth: Azure CLI credential                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 2: MCP Server (Tool Exposure)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASTMCP SERVER (spark_mcp_server.py)                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Protocol: MCP (Model Context Protocol)                    â”‚
â”‚  Transport: stdio (standard input/output)                  â”‚
â”‚  Why stdio? âœ“ Simple process-based communication          â”‚
â”‚             âœ“ No network ports needed                      â”‚
â”‚             âœ“ Perfect for VS Code agent integration        â”‚
â”‚                                                             â”‚
â”‚  Exposed Tools (5):                                        â”‚
â”‚    1. get_sparklens_recommendations(app_id)                â”‚
â”‚    2. get_fabric_recommendations(app_id)                   â”‚
â”‚    3. get_application_summary(app_id)                      â”‚
â”‚    4. get_bad_practice_applications(min_violations)        â”‚
â”‚    5. search_recommendations_by_category(category)         â”‚
â”‚                                                             â”‚
â”‚  Each tool â†’ KQL query â†’ Returns structured JSON          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why stdio (not HTTP/SSE)?**
- âœ… **VS Code Copilot requires stdio** for MCP server integration
- âœ… **No port conflicts** â€” no need to manage HTTP ports
- âœ… **Process isolation** â€” Each client gets dedicated server instance
- âœ… **Security** â€” No exposed network endpoints
- âŒ Only works for local processes (not remote clients)

### Layer 3: RAG System (Documentation Context)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AZURE AI SEARCH (RAG Document Store)                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Index: spark-docs-index                                   â”‚
â”‚  Documents: 4 markdown files                               â”‚
â”‚    â€¢ Spark best practices                                  â”‚
â”‚    â€¢ Resource profile configurations                       â”‚
â”‚    â€¢ Driver mode optimization                              â”‚
â”‚    â€¢ Lakehouse table maintenance                           â”‚
â”‚                                                             â”‚
â”‚  Search: Vector + keyword hybrid search                    â”‚
â”‚  Embeddings: text-embedding-ada-002                        â”‚
â”‚  Query: orchestrator.retriever.search(query, top_k=5)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 4: Agent Orchestrator (Brain)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SEMANTIC KERNEL ORCHESTRATOR (agent/orchestrator.py)      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Role: Multi-step reasoning agent                          â”‚
â”‚                                                             â”‚
â”‚  Pipeline:                                                  â”‚
â”‚    1. Intent Detection â†’ Pattern matching on user query   â”‚
â”‚    2. Tool Selection   â†’ Pick MCP tools or dynamic query   â”‚
â”‚    3. Data Retrieval   â†’ Execute Kusto queries            â”‚
â”‚    4. RAG Enrichment   â†’ Add documentation context         â”‚
â”‚    5. LLM Generation   â†’ GPT-4o synthesis                  â”‚
â”‚    6. Judge Validation â†’ Verify recommendations            â”‚
â”‚    7. Response Format  â†’ Structured markdown output        â”‚
â”‚                                                             â”‚
â”‚  Key Features:                                             â”‚
â”‚    â€¢ Session management (multi-turn conversations)        â”‚
â”‚    â€¢ Reference resolution ("show me", "that app")         â”‚
â”‚    â€¢ Dynamic KQL generation (LLM generates queries)       â”‚
â”‚    â€¢ Feedback loop (stores user ratings)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 5: LLM Judge (Quality Gate)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM JUDGE (agent/judge.py)                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Role: Validate and prioritize recommendations            â”‚
â”‚                                                             â”‚
â”‚  Inputs:                                                    â”‚
â”‚    â€¢ Kusto recommendations (sparklens + fabric)           â”‚
â”‚    â€¢ RAG documentation snippets                           â”‚
â”‚    â€¢ LLM-generated advice (if no Kusto data)              â”‚
â”‚                                                             â”‚
â”‚  Processing:                                               â”‚
â”‚    1. NEVER modify Kusto recommendations (preserve)       â”‚
â”‚    2. Score each recommendation (0-100)                    â”‚
â”‚    3. Assign priority (1=CRITICAL, 30=LOW)                â”‚
â”‚    4. Filter out generic/duplicate advice                  â”‚
â”‚    5. Add confidence scores                                â”‚
â”‚                                                             â”‚
â”‚  Output: validated_recommendations[] sorted by priority   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Critical Rule:** Judge NEVER changes Kusto data â€” only validates/prioritizes

---

## ğŸ–¥ï¸ User Interfaces

### Interface 1: Chainlit Web UI (Primary)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CHAINLIT UI (ui/app.py)                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Port: 8000                                                 â”‚
â”‚  Protocol: WebSocket (not stdio)                           â”‚
â”‚  Launch: chainlit run ui/app.py                            â”‚
â”‚                                                             â”‚
â”‚  Why Chainlit (not Gradio/Streamlit)?                     â”‚
â”‚  âœ… Built for AI chat interfaces (not general dashboards)  â”‚
â”‚  âœ… Async/await native (perfect for Semantic Kernel)       â”‚
â”‚  âœ… Action buttons (feedback: HELPFUL/NOT HELPFUL)         â”‚
â”‚  âœ… Multi-step progress indicators (cl.Step API)           â”‚
â”‚  âœ… Session management built-in                            â”‚
â”‚  âœ… Markdown + HTML rendering (rich formatting)            â”‚
â”‚  âœ… File uploads + integrations                            â”‚
â”‚                                                             â”‚
â”‚  Gradio would require:                                     â”‚
â”‚    â€¢ Manual session state handling                         â”‚
â”‚    â€¢ Custom async wrappers                                 â”‚
â”‚    â€¢ Less polished chat UX                                 â”‚
â”‚                                                             â”‚
â”‚  Streamlit would require:                                  â”‚
â”‚    â€¢ Page reloads on every interaction                     â”‚
â”‚    â€¢ No true async support                                 â”‚
â”‚    â€¢ Chat memory hack via st.session_state                 â”‚
â”‚                                                             â”‚
â”‚  Connection to MCP: INDIRECT                               â”‚
â”‚    Chainlit â†’ orchestrator.py â†’ MCP tools                 â”‚
â”‚    (Does NOT use stdio â€” direct Python imports)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Does Chainlit use stdio?** 
- âŒ **No** â€” Chainlit is a web framework that runs on WebSocket
- It calls `orchestrator.py` directly as Python functions
- The orchestrator then uses MCP tools internally
- Only VS Code agent uses stdio to communicate with MCP server

### Interface 2: VS Code Copilot Agent

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VS CODE COPILOT CHAT                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Config: .vscode/settings.json                             â”‚
â”‚  {                                                          â”‚
â”‚    "mcp.servers": {                                        â”‚
â”‚      "spark-advisor": {                                   â”‚
â”‚        "command": "python",                               â”‚
â”‚        "args": ["spark_mcp_server.py"]                   â”‚
â”‚      }                                                     â”‚
â”‚    }                                                       â”‚
â”‚  }                                                         â”‚
â”‚                                                             â”‚
â”‚  Why stdio (not HTTP)?                                    â”‚
â”‚  âœ… VS Code MCP spec requires stdio transport              â”‚
â”‚  âœ… Auto process management (launches/kills server)        â”‚
â”‚  âœ… Isolated per workspace                                 â”‚
â”‚                                                             â”‚
â”‚  Flow:                                                      â”‚
â”‚    User: @workspace analyze app_123                       â”‚
â”‚      â†“                                                      â”‚
â”‚    VS Code Copilot â†’ Launches spark_mcp_server.py         â”‚
â”‚      â†“                                                      â”‚
â”‚    MCP server â†’ Executes KQL query â†’ Returns JSON         â”‚
â”‚      â†“                                                      â”‚
â”‚    Copilot LLM â†’ Formats response â†’ Shows in chat         â”‚
â”‚                                                             â”‚
â”‚  Tools available: Same 5 MCP tools as Chainlit            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Interface 3: Python API

```python
# Direct orchestrator usage (for notebooks, automation)
from agent.orchestrator import SparkAdvisorOrchestrator

async def main():
    orchestrator = SparkAdvisorOrchestrator()
    result = await orchestrator.analyze_application("app_123")
    print(result["summary"])
```

---

## ğŸ”„ Data Flow Example

**User Query:** "Show me apps that took most amount of time"

### Chainlit UI Flow:
```
User Browser
  â†’ WebSocket (port 8000)
    â†’ Chainlit (ui/app.py)
      â†’ detect_intent("most time")
        â†’ orchestrator.chat()
          â†’ Pattern: "most time" â†’ top apps query
            â†’ KQL: sparklens_predictions | where "Current" 
              â†’ Kusto API (Azure CLI auth)
                â† Returns: [{app_id, duration, executors}]
              â† Parse results
            â† Format markdown table
          â† LLM adds context (optional)
        â† Returns response text
      â† Renders in chat UI
    â† WebSocket sends HTML/markdown
  â† Browser displays formatted table
```

### VS Code Agent Flow:
```
User (@workspace query)
  â†’ VS Code Copilot
    â†’ Launches: python spark_mcp_server.py
      â†’ stdio: {"method": "tools/call", "params": {...}}
        â†’ KQL query execution
          â†’ Kusto API
            â† Returns JSON
          â† Formats response
        â† stdio: {"result": {...}}
      â†’ Copilot LLM synthesizes natural language
    â† Shows in chat panel
```

---

## ğŸ¯ Key Technical Decisions

### 1. Why MCP (Model Context Protocol)?

**What is MCP?**
- Open protocol for exposing tools/data to AI agents
- Created by Anthropic, adopted by VS Code, Claude, others
- Alternative to OpenAI function calling (works across LLMs)

**Why we chose it:**
- âœ… **Standardized** â€” Works with multiple AI clients (not vendor-locked)
- âœ… **Composable** â€” Can combine multiple MCP servers
- âœ… **Type-safe** â€” Tools have JSON schema definitions
- âœ… **Discoverable** â€” Agents can list available tools
- âœ… **VS Code integration** â€” First-class support in Copilot

**FastMCP specifically:**
- Lightweight Python implementation
- Decorator-based tool registration (`@mcp.tool()`)
- Built-in stdio transport
- Minimal boilerplate

### 2. Why Chainlit for UI?

| Feature | Chainlit | Gradio | Streamlit |
|---------|----------|--------|-----------|
| Chat-first UI | âœ… Native | âš ï¸ Custom | âš ï¸ Custom |
| Async/await | âœ… Native | âŒ No | âŒ No |
| Streaming responses | âœ… Built-in | âš ï¸ Manual | âš ï¸ Manual |
| Action buttons | âœ… cl.Action | âš ï¸ Manual | âœ… st.button |
| Session management | âœ… cl.user_session | âŒ Manual | âœ… st.session_state |
| Progress steps | âœ… cl.Step | âŒ No | âš ï¸ st.spinner |
| HTML rendering | âœ… Full | âš ï¸ Limited | âš ï¸ Limited |
| File uploads | âœ… Built-in | âœ… Built-in | âœ… Built-in |
| Page reload on interaction | âŒ No | âŒ No | âœ… **Yes** (dealbreaker) |

**Decision:** Chainlit wins for **async-first chat experiences**

### 3. Why stdio for VS Code (not HTTP)?

**Options considered:**

| Transport | Pros | Cons | Use Case |
|-----------|------|------|----------|
| **stdio** | Simple, no ports, VS Code native | Local only | âœ… VS Code agent |
| **SSE (HTTP)** | Remote access, web-friendly | Port management, auth | Chainlit UI |
| **WebSocket** | Bi-directional, real-time | Complex, state management | Future: multi-client |

**Why we use stdio for VS Code:**
- That's what VS Code MCP spec requires
- Auto process lifecycle management
- No CORS/auth complexity

**Why Chainlit doesn't use stdio:**
- It's a web server (needs HTTP/WebSocket)
- Multiple concurrent users
- Stateful connections

### 4. Why Kusto (not SQL/MongoDB)?

| Feature | Kusto | PostgreSQL | MongoDB |
|---------|-------|------------|---------|
| Time-series queries | âœ… Optimized | âš ï¸ Slow | âŒ Poor |
| Petabyte scale | âœ… Native | âŒ No | âŒ No |
| Fabric integration | âœ… Built-in | âŒ No | âŒ No |
| KQL language | âœ… Powerful | SQL | JSON queries |
| Summarize/pivot | âœ… Native | âš ï¸ Complex | âš ï¸ Aggregation framework |

**Decision:** Kusto is **purpose-built for Spark telemetry analytics**

---

## ğŸ“Š Demo Flow Recommendation

### Part 1: Architecture Overview (5 min)
1. Show architecture diagram (5 layers)
2. Explain data flow: Kusto â†’ MCP â†’ Orchestrator â†’ UI
3. Highlight key tech: FastMCP, Semantic Kernel, Chainlit

### Part 2: Chainlit UI Demo (10 min)
1. **Query 1:** "Show me apps that took most amount of time"
   - Show: Intent detection, Kusto query, formatted results
   - Highlight: Numeric sorting fix (1.0x Current row, duration parsing)

2. **Query 2:** "Analyze application_1771441543262_0001"
   - Show: Progress steps (ğŸ“Š Fetching Kusto â†’ ğŸ“š RAG â†’ ğŸ¤– LLM)
   - Highlight: 3-tier output (Kusto âœ… â†’ RAG ğŸ“š â†’ LLM âš ï¸)

3. **Query 3:** "How many executor cores did app_XXX run with?"
   - Show: JSON parsing from SparkEventLogs
   - Highlight: Fixed column names (AppId, PropertiesJson)

4. **Feedback:** Click "HELPFUL" button
   - Show: Feedback stored for future ranking

### Part 3: VS Code Agent Demo (5 min)
1. Open VS Code Copilot Chat
2. Type: `@workspace analyze application_1771441543262_0001`
3. Show: MCP server auto-starts (stdio)
4. Show: Same tools, different interface

### Part 4: Technical Deep Dive (10 min)
1. **Show code:** `spark_mcp_server.py`
   - FastMCP decorator: `@mcp_server.tool()`
   - KQL query generation
   - JSON response structure

2. **Show code:** `agent/orchestrator.py`
   - Intent detection logic
   - Dynamic query generation (LLM creates KQL)
   - Judge validation pipeline

3. **Show code:** `.vscode/settings.json`
   - MCP configuration
   - stdio vs HTTP difference

### Part 5: Q&A Topics
- "Can we add more MCP tools?" â†’ Yes, decorator pattern
- "Can we use other LLMs?" â†’ Yes, Semantic Kernel abstraction
- "Can we deploy Chainlit to production?" â†’ Yes, Docker + Azure Container Apps
- "How do we add more RAG docs?" â†’ Run `rag/indexer.py`

---

## ğŸš€ Key Takeaways for Your Audience

1. **MCP is a game-changer** for building AI agents
   - Standardized tool protocol
   - Works across multiple AI platforms
   - Easy to extend (just add `@mcp.tool()`)

2. **Semantic Kernel** provides enterprise-grade orchestration
   - Multi-step reasoning
   - Session management
   - Pluggable LLMs

3. **Chainlit** is the best choice for AI chat UIs
   - Async-first (unlike Streamlit)
   - Chat-native (unlike Gradio)
   - Production-ready

4. **Kusto + RAG + LLM Judge** ensures quality
   - Tier 1: Ground truth (Kusto) â€” never modified
   - Tier 2: Official docs (RAG) â€” adds context
   - Tier 3: LLM fallback â€” clearly labeled

5. **Multi-interface support** maximizes reach
   - Analysts â†’ Chainlit web UI
   - Developers â†’ VS Code agent
   - Automation â†’ Python API

---

## ğŸ“ File Reference for Demo

**Core files to show:**
- `spark_mcp_server.py` â€” MCP tool definitions (150 lines)
- `agent/orchestrator.py` â€” Intent detection + orchestration (1800 lines)
- `agent/judge.py` â€” LLM validation logic (400 lines)
- `ui/app.py` â€” Chainlit interface (2000 lines)
- `.vscode/settings.json` â€” VS Code MCP config (5 lines)

**Key features to demo:**
- Typo tolerance: "analyz" works (fuzzy matching)
- Progress indicators: cl.Step API shows real-time status
- Feedback buttons: HELPFUL/NOT HELPFUL/PARTIAL
- Multi-source display: Kusto âœ… | RAG ğŸ“š | LLM âš ï¸

---

Good luck with your demo! ğŸ¤
